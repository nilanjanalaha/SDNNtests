al.est <- ifelse(abs(al.mai)>0, 1, 0)
be.est <- ifelse(abs(be.mai)>0, 1, 0)
#Calculating fraction of support recovered (Why should we do that?)
p.al <- length(which(al.est==truesup_al))/length(al)
p.be <- length(which(be.est==truesup_be))/length(be)
p.al.pmai[i,j] <- p.al
p.be.pmai[i,j] <- p.be
#------------# Mai's estimator after cleaning------------
sxy <- cov(x,y)
tb <- crossprod(sxy, al.mai)
ta <- crossprod(t(sxy), be.mai)
#general method's tau
gen.tau <- Cg*log(2*s)/s #if s=1, tis becomes 0
al.est <- ifelse(abs(ta)>gen.tau, 1, 0)
be.est <- ifelse(abs(tb)>gen.tau, 1, 0)
#Calculating fraction of support recovered (Why should we do that?)
p.al <- length(which(al.est==truesup_al))/length(al)
p.be <- length(which(be.est==truesup_be))/length(be)
p.al.cmai[i,j] <- p.al
p.be.cmai[i,j] <- p.be
}
}
# listing the matrices
al_list <- list(p.al.ct, p.al.pmai, p.al.cmai)
be_list <- list(p.be.ct, p.be.pmai, p.be.cmai)
method <- c("CT", "SCCA", "Cleaned_SCCA")
# Processing the matrices
process_list <- function(l)
{
long <- numeric()
for (i in 1: length(l))
{
temp <- t(l[[i]])
meth.c <- rep(method[i], length(frac))
temp <- data.frame(meth.c, frac, temp)
long <- rbind(long, temp)
}
colnames(long) <- c("Method", "frac", pv)
long
}
# Clubbing al vectors
p.al <- process_list(al_list)
p.be <- process_list(be_list)
p.al
source('~/Google Drive/harvard cluster/Ramu/support.R')
C1 = 1 #Theorem 3, positive
C2 = 3 #Theorem 3, positive (I think greater than C1)
tau = 1 # Theorem 4, positive
nl = 1/4 # Theorem 4, exponet term for log s, takes value in (0,1/2)
rho <-0.5
Cg <- 1 #Theorem 1
#----------- The vectors and matrices ---------------------
# vectors of p and q, and n
pv <- qv <- c(300, 400, 500)
nv <- c(300, 400, 500)
# s/sqrt(n) values
frac <- seq(0.01, 0.5, length.out = 10)
p.al.ct <- p.be.ct <- matrix(0, length(pv), length(frac))
p.al.pmai <-  p.al.cmai <-  p.be.pmai <-  p.be.cmai <- p.al.ct
# for loop for calling support recovery function
for (i in 1: length(pv))
{
n <- nv[i]
p <- pv[i]
q <- qv[i]
sv <- ceiling(sqrt(n)*frac)
for (j in 1:length(sv))
{
s <- sv[j]
al <- be <- vector(mode="numeric", length=pv[i])
#True support, sample uniformly from 1:p
truesup_a <-  1:sv[j]
truesup_b <- 1: sv[j]
# hard sparsity but letting entries be 1 or -1
# Presenting the support as a vector of 0's and 1's.
al[truesup_a] <- 1
truesup_al <- abs(al)
v <- rep(-1, sv[j])
for(k in 1: sv[j])
{
if((k %% 2) == 0)
v[k] <- 100
}
be[truesup_b] <- v
truesup_be <- abs(be)
#Normalize alpha and beta
al <- al/sqrt(sum(al^2))
be <- be/sqrt(sum(be^2))
#Creating the true covariance matrix
truesigma <-  Sigma_mat(p,q,al,be, rho)
#Simulating the data
Z <- rmvnorm(n, sigma = truesigma)
x <- Z[,1:p]
y <- Z[,(p+1):(p+q)]
#---------- CT-----------------------#
# estimating support
#The parameters
t <- givet(s, p, q, C1, C2)
tp <- tau* (log(2*s))^(0.5+nl)/(2*s)
temp <- give_support(x, y, t, tp)
al.est <- temp[,1]
be.est <- temp[,2]
#Calculating fraction of support recovered (Why should we do that?)
p.al <- length(which(al.est==truesup_al))/length(al)
p.be <- length(which(be.est==truesup_be))/length(be)
p.al.ct[i,j] <- p.al
p.be.ct[i,j] <- p.be
#------- pati Mai estimator---------------
temp <- SCCA(x,y, lambda.alpha = sqrt(log(p+q)/n),
lambda.beta = sqrt(log(p+q)/n))
al.mai <- temp$alpha
be.mai <- temp$beta
al.est <- ifelse(abs(al.mai)>0, 1, 0)
be.est <- ifelse(abs(be.mai)>0, 1, 0)
#Calculating fraction of support recovered (Why should we do that?)
p.al <- length(which(al.est==truesup_al))/length(al)
p.be <- length(which(be.est==truesup_be))/length(be)
p.al.pmai[i,j] <- p.al
p.be.pmai[i,j] <- p.be
#------------# Mai's estimator after cleaning------------
sxy <- cov(x,y)
tb <- crossprod(sxy, al.mai)
ta <- crossprod(t(sxy), be.mai)
#general method's tau
gen.tau <- Cg*log(2*s)/s #if s=1, tis becomes 0
al.est <- ifelse(abs(ta)>gen.tau, 1, 0)
be.est <- ifelse(abs(tb)>gen.tau, 1, 0)
#Calculating fraction of support recovered (Why should we do that?)
p.al <- length(which(al.est==truesup_al))/length(al)
p.be <- length(which(be.est==truesup_be))/length(be)
p.al.cmai[i,j] <- p.al
p.be.cmai[i,j] <- p.be
}
}
# listing the matrices
al_list <- list(p.al.ct, p.al.pmai, p.al.cmai)
be_list <- list(p.be.ct, p.be.pmai, p.be.cmai)
method <- c("CT", "SCCA", "Cleaned_SCCA")
# Processing the matrices
process_list <- function(l)
{
long <- numeric()
for (i in 1: length(l))
{
temp <- t(l[[i]])
meth.c <- rep(method[i], length(frac))
temp <- data.frame(meth.c, frac, temp)
long <- rbind(long, temp)
}
colnames(long) <- c("Method", "frac", pv)
long
}
# Clubbing al vectors
p.al <- process_list(al_list)
p.be <- process_list(be_list)
p.al
pow=p.al
sd=pow
longpow <- melt(pow, id.vars = 1:2, variable.name = "p", value.name="estimate")
longsd <- melt(sd, id.vars = 1:2, variable.name = "p", value.name="sd")
mydata <- data.frame(longpow, sd=longsd$sd)
#errorbar
lb <- mydata$estimate - 2*mydata$sd
lb <- ifelse(lb>0, lb, 0)
ub <- mydata$estimate + 2*mydata$sd
ub <- ifelse(ub<1, ub, 1)
mydata <- cbind(mydata, lb, ub)
# factoring Method
mydata$Method <- factor(mydata$Method, levels=c("SCCA","Cleaned_SCCA","CT"))
g <- ggplot(data=mydata, aes(x=frac, y=estimate, color=p))
g <- g + geom_line() + facet_grid(cols = vars(Method))
g <- g+ labs(x=expression(s/sqrt(n)), y="Proportion of recoverd support")
#error-bar
#g <- g + geom_errorbar(data=mydata, aes(ymin=lb, ymax=ub), width=0.02)
# change theme and text size
tts <- 15
ts <- 15
tl <- 15
g <- g + theme_bw() + theme(legend.position = "top", axis.title= element_text(size= tts),
axis.text.y=element_text(size= ts),
#axis.text.x=element_text(size= ts),
legend.text=element_text(size= tl),
#strip.text.x=element_text(size= ts),
legend.title=element_text(size= tts))
dest3 <- paste(fp, "/Ramu/support/main_", where,"/",where,"plot.pdf", sep="")
ggsave(dest3, device="pdf", width = 9, height=3.5, units = "in")
g
my.plot <- function(pow,sd)
{
longpow <- melt(pow, id.vars = 1:2, variable.name = "p", value.name="estimate")
longsd <- melt(sd, id.vars = 1:2, variable.name = "p", value.name="sd")
mydata <- data.frame(longpow, sd=longsd$sd)
#errorbar
lb <- mydata$estimate - 2*mydata$sd
lb <- ifelse(lb>0, lb, 0)
ub <- mydata$estimate + 2*mydata$sd
ub <- ifelse(ub<1, ub, 1)
mydata <- cbind(mydata, lb, ub)
# factoring Method
mydata$Method <- factor(mydata$Method, levels=c("SCCA","Cleaned_SCCA","CT"))
g <- ggplot(data=mydata, aes(x=frac, y=estimate, color=p))
g <- g + geom_line() + facet_grid(cols = vars(Method))
g <- g+ labs(x=expression(s/sqrt(n)), y="Proportion of recoverd support")
#error-bar
#g <- g + geom_errorbar(data=mydata, aes(ymin=lb, ymax=ub), width=0.02)
# change theme and text size
tts <- 15
ts <- 15
tl <- 15
g <- g + theme_bw() + theme(legend.position = "top", axis.title= element_text(size= tts),
axis.text.y=element_text(size= ts),
#axis.text.x=element_text(size= ts),
legend.text=element_text(size= tl),
#strip.text.x=element_text(size= ts),
legend.title=element_text(size= tts))
dest3 <- paste(fp, "/Ramu/support/main_", where,"/",where,"plot.pdf", sep="")
print(g)
}
my.plot(p.al, p.al)
my.plot(p.beta, p.beta)
my.plot(p.al, p.al)
my.plot(p.be, p.be)
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
?setequal
setequal(sort(al.est),sort(truesup_al))
x=c(1,3,2)
y=1:3
setequal(x,y)
as.numeric(setequal(x,y))
source('~/Google Drive/harvard cluster/Ramu/support.R')
p.al
source('~/Google Drive/harvard cluster/Ramu/support.R')
sv
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
p.be <- length(which(be.est[truesup_b]==1))/s
source('~/Google Drive/harvard cluster/Ramu/support.R')
p.al.pmai[i,j] <- p.al
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
sv
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
source('~/Google Drive/harvard cluster/Ramu/support.R')
x=rnorm(100)
x=sort(x)
calc_mode(x, 1)
temp=calc_mode(x, 1)
length(temp$x.knots)
length(temp$F.knots)
length(temp$f.knots)
temp$F.knots
x[1:10]
temp$x.knots
temp$f.knots
document()
setwd("~/Dropbox/Vaccine_trial")
document()
setwd("~/Dropbox/Vaccine_trial/SDNNtests")
document()
source('~/Google Drive/harvard cluster/Ramu/compile_estimate.R')
?calc_mode
??calc_mode
library(SDNNtests)
?calc_mode
setwd("..")
getwd()
install("SDNNtests")
?SDNNtests
??SDNNtests
library(SDNNtests)
??SDNNtests
?SDNN
?calc_mode
library(devtools)
document()
cd("SDNNtests")
setwd("SDNNtests")
devtools::document()
?SDNN
?calc_mode
document()
document()
?calc_mode
??calc_mode
setwd("..")
install("SDNNtests")
documents()
document()
setwd("SDNNtests")
document()
?calc_mode
??calc_mode
document()
?calc_mode
document()
document()
?SDNN
?calc_mode
?SDNN
load_all(".")
?SDNN
setwd("..")
install("SDNNtests")
?SDNN
library(SDNN)
library(SDNNtests)
setwd("SDNNtests")
?SDNN
document()
?SDNN
?SDNN
library(SDNNtests)
library(SDNNtests)
?SDNN
devtools::build_manual()
pack <- "SDNNtests"
path <- find.package(pack)
wd <- getwd()
system(paste0(shQuote(file.path(R.home("bin"), "R")),
" CMD", " Rd2pdf --force -o ", wd ,"/inst/doc/caspr-manual.pdf ",
shQuote(path))
)
devtools::check(manual=TRUE)
?SDNN
document()
library(roxygen2)
library(devtools)
document()
devtools::build_manual()
devtools::check(manual=TRUE)
devtools::check(manual=TRUE)
error()
document()
devtools::check(manual=TRUE)
document()
devtools::check(manual=TRUE)
library(SDNNtests)
devtools::check()
use_mit_license("Nilanjana Laha")
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
build_manual("SDNNtests")
setwd("..")
build_manual("SDNNtests")
check(add_manual=TRUE)
check(build_manual=TRUE)
setwd("SDNNtests")
check(build_manual=TRUE)
devtools::check(manual=TRUE)
devtools::check(manual=TRUE)
?SDNN
document()
?SDNN
library(SDNNtests)
?SDNN
library(SDNNtests)
?SDNN
check()
library(devtools)
check()
?check
check(manual="TRUE")
check(manual=TRUE)
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
document()
?SDNN
library(SDNNtests)
?SDNN
build_manual(pkg="SDNNtests")
setwd("..")
build_manual(pkg="SDNNtests")
build_manual(pkg="SDNNtests")
document()
document(SDNNtests)
?document
document("SDNNtests")
build_manual(pkg="SDNNtests")
document()
library(devtools)
document()
?SDNN
git init
install.packages("pacman")
# this command checks if you have the packages already installed,
# then installs the missing packages, then loads the libraries
pacman::p_load(knitr, rmarkdown, devtools, roxygen2, usethis)
# identify yourself to Git with the usethis package
# use the exact same username and email associated
# with your GitHub account
usethis::use_git_config(user.name = "nilanjanalaha", user.email = "nilanjanaaa.laha@gmail.com")
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
x=rnorm(100)
y=rnorm(500)
hd.uni(x,y)
library(SDNNtests)
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
hd.uni(x,y)
source('~/Dropbox/Vaccine_trial/SDShape/R/Grenander function.R')
hd.uni(x,y)
qnorm(0.975)
source('~/Dropbox/Vaccine_trial/SDShape/R/ci.R')
source('~/Dropbox/Vaccine_trial/SDShape/R/ci.R')
hell.ci(x, y, 0.05)
temp=hell.ci(x, y, 0.05)
temp$lc.ci
source('~/Dropbox/Vaccine_trial/SDShape/R/ci.R')
temp=hell.ci(x, y, 0.05)
summary(temp)
temp$lc.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
source('~/Dropbox/Vaccine_trial/SDShape/R/ci.R')
hell.ci(x,y)$lc.uni
hell.ci(x,y)$lc.ci
library(SDNNtests)
?hell.ci
library(SDNNtests)
getwd()
document()
library(devtools)
document()
rm(list = c("Grenander_general", "grenander.inter", "grenander.inter.density", "hd.lc", "hd.lc.sm", "hd.uni", "Hell", "my_grenander"))
document()
library(SDNNtests)
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/R/ci.R')
source('~/Dropbox/Vaccine_trial/SDNNtests/R/ci.R')
library(SDNNtests)
document()
getwd()
?hd.uni
?hd.lc.sm
devtools::check()
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/main.R')
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/ci.R')
library(SDNNtests)
check()
build_manual()
build_manual()
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
?do_description
library(SDNNtests)
?do_description
library(SDNNtests)
?hell.ci
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/hd.birge.R')
library(SDNNtests)
?SDNN
source('~/Dropbox/Vaccine_trial/SDShape/SDNNtests/R/main.R')
library(SDNNtests)
check()
library(SDNNtests)
check()
check()
build_manual()
build_manual(".")
build_manual("SDNNtests")
build_manual("SDNNtests")
getwd()
